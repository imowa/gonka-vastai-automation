#!/usr/bin/env python3
"""
PoC Scheduler
Orchestrates the complete PoC automation workflow:
1. Monitor blockchain for PoC timing
2. Rent GPU 30 minutes before PoC
3. Deploy Gonka MLNode
4. Run PoC Sprint
5. Stop GPU automatically
"""

import sys
import os
import time
import json
import logging
import requests
from datetime import datetime, timedelta
from typing import Optional, Dict
from dataclasses import dataclass
import importlib.util
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# Load our custom modules
def load_module(name, path):
    spec = importlib.util.spec_from_file_location(name, path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

poc_monitor_module = load_module("poc_monitor", "scripts/1_poc_monitor.py")
vastai_module = load_module("vastai_manager", "scripts/2_vastai_manager.py")

PoCMonitor = poc_monitor_module.PoCMonitor
VastAIManager = vastai_module.VastAIManager

from env_loader import load_env

load_env('config/.env')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/poc_scheduler.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class PoCSession:
    """Represents a PoC Sprint session"""
    epoch_id: int
    instance_id: Optional[int] = None
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    status: str = "pending"  # pending, running, completed, failed
    total_cost: float = 0.0
    gpu_type: Optional[str] = None


class PoCScheduler:
    """Main scheduler for automated PoC execution"""
    
    def __init__(self):
        self.monitor = PoCMonitor()
        self.vastai = VastAIManager()
        
        # Configuration
        self.prep_time = int(os.getenv('POC_PREP_TIME', '1800'))  # 30 minutes
        self.max_duration = int(os.getenv('MAX_POC_DURATION', '10800'))  # 3 hours safety
        self.check_interval = int(os.getenv('POC_CHECK_INTERVAL', '300'))  # 5 minutes
        self.max_daily_spend = float(os.getenv('MAX_DAILY_SPEND', '2.0'))
        self.admin_api_url = os.getenv('GONKA_ADMIN_API_URL', 'http://localhost:9200')
        self.proxy_host = os.getenv("VPS_IP", "198.74.55.121")
        self.proxy_port = int(os.getenv("HYPERBOLIC_PROXY_PORT", os.getenv("PROXY_PORT", "8080")))
        self.proxy_health_path = os.getenv("PROXY_HEALTH_PATH", "/health")
        self.proxy_node_id = os.getenv("MLNODE_ID", os.getenv("NODE_ID", "hyperbolic-proxy-1"))
        self.proxy_model_name = os.getenv(
            "HYPERBOLIC_MODEL",
            os.getenv("MLNODE_MODEL", os.getenv("MODEL_NAME", "Qwen/QwQ-32B"))
        )
        self.proxy_inference_segment = os.getenv("INFERENCE_SEGMENT", "/v1")
        self.proxy_poc_segment = os.getenv("POC_SEGMENT", "/api/v1")
        self.proxy_hardware_type = os.getenv("HARDWARE_TYPE", "Hyperbolic-API")
        self.proxy_hardware_count = int(os.getenv("HARDWARE_COUNT", "1"))
        self.instance_ready_timeout = int(os.getenv("VASTAI_INSTANCE_READY_TIMEOUT", "1800"))
        
        # State
        self.current_session: Optional[PoCSession] = None
        self.daily_spend = 0.0
        self.last_reset_date = datetime.now().date()
        
        logger.info("PoC Scheduler initialized")
        logger.info(f"Prep time: {self.prep_time}s ({self.prep_time//60} minutes)")
        logger.info(f"Max duration: {self.max_duration}s ({self.max_duration//3600} hours)")
        logger.info(f"Check interval: {self.check_interval}s ({self.check_interval//60} minutes)")
        logger.info(f"Max daily spend: ${self.max_daily_spend}")
        logger.info(
            "Instance ready timeout: %ss (%s minutes)",
            self.instance_ready_timeout,
            self.instance_ready_timeout // 60,
        )
    
    def reset_daily_spend(self):
        """Reset daily spend counter at midnight"""
        today = datetime.now().date()
        if today > self.last_reset_date:
            logger.info(f"Daily spend reset: ${self.daily_spend:.2f} ‚Üí $0.00")
            self.daily_spend = 0.0
            self.last_reset_date = today
    
    def check_spending_limit(self) -> bool:
        """Check if we're within spending limits"""
        if self.daily_spend >= self.max_daily_spend:
            logger.warning(f"Daily spending limit reached: ${self.daily_spend:.2f}")
            return False
        return True
    
    def select_best_gpu(self) -> Optional[int]:
        """
        Search for and select the best available GPU instance
        
        Returns:
            Offer ID if found, None otherwise
        """
        logger.info("Searching for available GPU instances...")
        
        offers = self.vastai.search_offers(limit=5)
        
        if not offers:
            logger.error("No GPU instances available")
            return None
        
        # Filter by VRAM requirement (need 40GB+ total)
        valid_offers = [o for o in offers if (o.gpu_ram * o.num_gpus) >= 40000]
        
        if not valid_offers:
            logger.error("No instances with 40GB+ VRAM found")
            logger.info("Available offers didn't meet VRAM requirements")
            return None
        
        # Select cheapest valid offer
        best_offer = valid_offers[0]
        logger.info(f"Selected: {best_offer}")
        logger.info(f"Cost estimate for 15 min: ${(best_offer.dph_total / 60) * 15:.3f}")
        
        return best_offer.id

    def _proxy_base_url(self) -> str:
        return f"http://{self.proxy_host}:{self.proxy_port}"

    def check_inference_proxy_health(self) -> bool:
        """Check inference proxy health endpoint"""
        url = f"{self._proxy_base_url()}{self.proxy_health_path}"
        try:
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                logger.info(f"‚úÖ Inference proxy healthy at {url}")
                return True
            logger.warning(f"‚ö†Ô∏è Inference proxy health check failed: {response.status_code} {response.text}")
            return False
        except requests.RequestException as e:
            logger.warning(f"‚ö†Ô∏è Inference proxy health check failed: {e}")
            return False

    def is_inference_proxy_registered(self) -> bool:
        """Check if inference proxy is registered with Network Node"""
        try:
            response = requests.get(f"{self.admin_api_url}/admin/v1/nodes", timeout=10)
            response.raise_for_status()
            nodes = response.json()
            for node_data in nodes:
                node_info = node_data.get('node', {})
                if node_info.get('id') == self.proxy_node_id:
                    return True
        except requests.RequestException as e:
            logger.warning(f"‚ö†Ô∏è Failed to check proxy registration: {e}")
        return False

    def register_inference_proxy(self) -> bool:
        """Register inference proxy with Network Node"""
        payload = {
            "id": self.proxy_node_id,
            "host": self.proxy_host,
            "inference_port": self.proxy_port,
            "inference_segment": self.proxy_inference_segment,
            "poc_port": self.proxy_port,
            "poc_segment": self.proxy_poc_segment,
            "max_concurrent": 100,
            "models": {
                self.proxy_model_name: {}
            },
            "hardware": [
                {"type": self.proxy_hardware_type, "count": self.proxy_hardware_count}
            ]
        }

        try:
            logger.info(f"Registering inference proxy node {self.proxy_node_id}")
            response = requests.post(
                f"{self.admin_api_url}/admin/v1/nodes",
                headers={"Content-Type": "application/json"},
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            logger.info(f"‚úÖ Inference proxy registered: {self.proxy_node_id}")
            return True
        except requests.RequestException as e:
            logger.warning(f"‚ö†Ô∏è Failed to register inference proxy: {e}")
            if hasattr(e, 'response') and e.response is not None:
                logger.warning(f"Response: {e.response.text}")
            return False

    def ensure_inference_proxy_registered(self) -> None:
        """Ensure inference proxy is registered, re-register if missing"""
        if self.is_inference_proxy_registered():
            logger.info("‚úÖ Inference proxy already registered")
            return

        logger.warning("‚ö†Ô∏è Inference proxy not registered; attempting to register")
        self.register_inference_proxy()
    
    def start_gpu_instance(self, offer_id: int) -> Optional[int]:
        """
        Start a GPU instance
        
        Returns:
            Instance ID if successful, None otherwise
        """
        logger.info(f"Creating instance from offer {offer_id}...")
        
        # Docker image with Gonka MLNode
        image = os.getenv('DOCKER_IMAGE', 'nvidia/cuda:12.1.0-base-ubuntu22.04')
        disk = int(os.getenv('VASTAI_DISK_SIZE', '50'))
        
        # Startup script to prepare the instance
        onstart = """#!/bin/bash
echo "Instance started at $(date)"
nvidia-smi
echo "Ready for PoC Sprint"
"""
        
        instance_id = self.vastai.create_instance(
            offer_id=offer_id,
            image=image,
            disk=disk,
            onstart=onstart
        )
        
        if not instance_id:
            logger.error("Failed to create instance")
            return None
        
        logger.info(f"Instance {instance_id} created, waiting for ready state...")
        
        # Wait for instance to be ready
        if not self.vastai.wait_for_ready(instance_id, timeout=self.instance_ready_timeout):
            logger.error(f"Instance {instance_id} failed to start")
            # Try to destroy failed instance
            self.vastai.destroy_instance(instance_id)
            return None
        
        return instance_id
    
    def run_poc_sprint(self, instance_id: int) -> bool:
        """
        Run PoC Sprint using remote vLLM on GPU
        Network Node talks directly to remote vLLM (no local MLNode needed)
        
        Returns:
            True if successful, False otherwise
        """
        logger.info(f"Running PoC Sprint with remote vLLM on instance {instance_id}")
        
        try:
            # Import remote vLLM manager
            spec = importlib.util.spec_from_file_location("vllm_manager", "scripts/5_vllm_proxy_manager.py")
            vllm_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(vllm_module)
            RemoteVLLMManager = vllm_module.RemoteVLLMManager
            
            vllm_manager = RemoteVLLMManager()
            
            # Step 1: Get SSH connection to GPU
            logger.info("Step 1: Connecting to GPU instance...")
            ssh_info = vllm_manager.get_ssh_connection(self.vastai, instance_id)
            
            if not ssh_info:
                logger.error("Failed to get SSH connection")
                return False
            
            logger.info(f"‚úÖ Connected: {ssh_info['host']}:{ssh_info['port']}")
            
            # Step 2: Start vLLM on remote GPU
            logger.info("Step 2: Starting vLLM on remote GPU...")
            vllm_host = vllm_manager.start_remote_vllm(ssh_info, instance_id)
            
            if not vllm_host:
                logger.error("Failed to start vLLM")
                return False
            
            logger.info(f"‚úÖ vLLM ready at {vllm_host}")
            
            # Step 3: Register remote vLLM as MLNode
            logger.info("Step 3: Registering remote vLLM with Network Node...")
            if not self.check_inference_proxy_health():
                logger.warning("‚ö†Ô∏è Inference proxy is down; proceeding with PoC registration")
            if not vllm_manager.register_remote_mlnode(vllm_host, instance_id):
                logger.error("Failed to register remote MLNode")
                vllm_manager.stop_remote_vllm(ssh_info)
                return False
            
            logger.info("‚úÖ Remote MLNode registered")
            
            # Step 4: Wait for PoC to complete
            logger.info("Step 4: Monitoring PoC progress...")
            success = vllm_manager.wait_for_poc_completion(timeout=900)
            
            if success:
                logger.info("‚úÖ PoC Sprint completed!")
            else:
                logger.warning("‚ö†Ô∏è  PoC Sprint timed out")
            
            # Step 5: Cleanup
            logger.info("Step 5: Cleanup...")
            vllm_manager.unregister_remote_mlnode(instance_id)
            vllm_manager.stop_remote_vllm(ssh_info)
            self.ensure_inference_proxy_registered()
            
            logger.info("‚úÖ Cleanup complete")
            return success
            
        except Exception as e:
            logger.error(f"Error during PoC Sprint: {e}", exc_info=True)
            return False
    
    def stop_gpu_instance(self, instance_id: int) -> bool:
        """Stop and destroy GPU instance"""
        logger.info(f"Stopping instance {instance_id}...")
        
        # Get final cost
        cost = self.vastai.get_instance_cost(instance_id)
        if cost:
            logger.info(f"Total cost for this session: ${cost:.3f}")
            self.daily_spend += cost
            if self.current_session:
                self.current_session.total_cost = cost
        
        # Stop the instance
        success = self.vastai.destroy_instance(instance_id)
        
        if success:
            logger.info(f"‚úÖ Instance {instance_id} stopped")
        else:
            logger.warning(f"Failed to stop instance {instance_id}")
        
        return success
    
    def execute_poc_cycle(self, epoch_id: int):
        """Execute a complete PoC cycle"""
        logger.info("="*60)
        logger.info(f"Starting PoC cycle for epoch {epoch_id}")
        logger.info("="*60)
        
        # Create session
        self.current_session = PoCSession(epoch_id=epoch_id)
        self.current_session.start_time = time.time()
        self.current_session.status = "running"
        
        try:
            # Step 1: Check spending limit
            if not self.check_spending_limit():
                logger.error("Cannot start PoC: spending limit reached")
                self.current_session.status = "failed"
                return
            
            # Step 2: Select GPU
            offer_id = self.select_best_gpu()
            if not offer_id:
                logger.error("Cannot start PoC: no GPU available")
                self.current_session.status = "failed"
                return
            
            # Step 3: Start GPU instance
            instance_id = self.start_gpu_instance(offer_id)
            if not instance_id:
                logger.error("Cannot start PoC: instance creation failed")
                self.current_session.status = "failed"
                return
            
            self.current_session.instance_id = instance_id
            
            # Step 4: Run PoC Sprint
            success = self.run_poc_sprint(instance_id)
            
            if success:
                self.current_session.status = "completed"
                logger.info("‚úÖ PoC cycle completed successfully")
            else:
                self.current_session.status = "failed"
                logger.error("‚ùå PoC cycle failed")
            
        except Exception as e:
            logger.error(f"Error during PoC cycle: {e}", exc_info=True)
            self.current_session.status = "failed"
        
        finally:
            # Always stop the GPU instance
            if self.current_session.instance_id:
                self.stop_gpu_instance(self.current_session.instance_id)
            
            self.current_session.end_time = time.time()
            duration = self.current_session.end_time - self.current_session.start_time
            
            logger.info("="*60)
            logger.info(f"PoC cycle summary:")
            logger.info(f"  Status: {self.current_session.status}")
            logger.info(f"  Duration: {duration/60:.1f} minutes")
            logger.info(f"  Cost: ${self.current_session.total_cost:.3f}")
            logger.info(f"  Daily spend: ${self.daily_spend:.2f} / ${self.max_daily_spend}")
            logger.info("="*60)
    
    def run(self):
        """Main scheduler loop"""
        logger.info("="*60)
        logger.info("  PoC Scheduler Started")
        logger.info("="*60)
        logger.info("")
        logger.info("Monitoring blockchain for PoC timing...")
        logger.info(f"Will start GPU {self.prep_time//60} minutes before PoC")
        logger.info("")
        
        last_epoch = None
        
        while True:
            try:
                # Reset daily spend at midnight
                self.reset_daily_spend()
                
                # Get blockchain status
                status = self.monitor.get_status()
                
                if status['status'] != 'active':
                    logger.error("Cannot fetch blockchain data")
                    time.sleep(60)
                    continue
                
                current_epoch = status['current_epoch']
                next_epoch = status['next_epoch']
                seconds_to_poc = status['seconds_to_poc']
                should_start = status['should_start_gpu']
                
                # Log status
                hours = seconds_to_poc // 3600
                minutes = (seconds_to_poc % 3600) // 60
                logger.info(f"Epoch {current_epoch} | Phase: {status['current_phase']} | Next PoC: {hours}h {minutes}m")
                
                # Check if we should start GPU
                if should_start and next_epoch != last_epoch:
                    logger.warning(f"üö® PoC Sprint approaching! Starting GPU...")
                    self.execute_poc_cycle(next_epoch)
                    last_epoch = next_epoch
                elif should_start:
                    logger.info("Already processed this epoch, waiting for next...")
                
            except KeyboardInterrupt:
                logger.info("\n‚ö†Ô∏è  Shutdown requested")
                if self.current_session and self.current_session.instance_id:
                    logger.info("Stopping active GPU instance...")
                    self.stop_gpu_instance(self.current_session.instance_id)
                break
            
            except Exception as e:
                logger.error(f"Error in main loop: {e}", exc_info=True)
            
            # Wait before next check
            time.sleep(self.check_interval)


if __name__ == "__main__":
    try:
        # Create logs directory if it doesn't exist
        os.makedirs('logs', exist_ok=True)
        
        scheduler = PoCScheduler()
        scheduler.run()
    
    except KeyboardInterrupt:
        logger.info("\nShutdown complete")
    except Exception as e:
        logger.error(f"Fatal error: {e}", exc_info=True)
        sys.exit(1)
